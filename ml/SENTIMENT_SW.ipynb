{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SENTIMENT_SW.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kmy22Of4SZSh"
      },
      "source": [
        "\n",
        "\n",
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/SENTIMENT_SW.ipynb)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRsj9Vs4S5dM"
      },
      "source": [
        "# **Sentiment Analysis of Swahili texts**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMURhBz4ZwM6"
      },
      "source": [
        "## 1. Colab Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qyYMEtv59sox",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddc1ac4b-15f5-4c9c-fd70-60851ec7e016"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 212.4 MB 69 kB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 531 kB 25.2 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 198 kB 70.0 MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Install PySpark and Spark NLP\n",
        "! pip install -q pyspark==3.1.2 spark-nlp"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o78aqL2VTOFU"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as F\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.base import *\n",
        "import sparknlp\n",
        "from sparknlp.pretrained import PretrainedPipeline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUtHfXX6TT5T"
      },
      "source": [
        "## 2. Start Spark Session"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjMiR2b6TOM9"
      },
      "source": [
        "spark = sparknlp.start()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-me64q5WTex8"
      },
      "source": [
        "## 3. Some sample examples"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_list=[\"\"\"Tukio bora katika sinema ilikuwa wakati Gerardo anajaribu kupata wimbo ambao unaendelea kupitia kichwa chake.\"\"\",\"\"\"Ni dharau kwa akili ya mtu na upotezaji mkubwa wa pesa\"\"\",\"\"\"Kris Kristoffersen ni mzuri kwenye sinema hii na kweli hufanya tofauti.\"\"\",\"\"\"Hadithi yenyewe ni ya kutabirika tu na ya uvivu.\"\"\",\"\"\"Ninapendekeza hizi kwa kuwa zinaonekana nzuri sana, kifahari na nzuri\"\"\",\"\"\"Safaricom si muache kucheza na mkopo wa nambari yangu tafadhali. mnanifilisishaðŸ˜“ðŸ˜“ðŸ˜¯\"\"\",\"\"\"Bidhaa ilikuwa bora na inafanya kazi vizuri kuliko ya verizon na bei ilikuwa rahisi \"\"\",\"\"\"Siwezi kuona jinsi sinema hii inavyoweza kuwa msukumo kwa mtu yeyote kushinda woga na kukataliwa.\"\"\",\"\"\"Sinema hii inasawazishwa vizuri na vichekesho na mchezo wa kuigiza na nilijifurahisha sana.\"\"\"]"
      ],
      "metadata": {
        "id": "moNYRtej_8AD"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lwQIiLPTzat"
      },
      "source": [
        "## 4. Define Spark NLP pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GImc405eTOSK",
        "outputId": "a3318d02-67f0-4203-b7d9-87888346e115"
      },
      "source": [
        "document_assembler = DocumentAssembler() \\\n",
        "      .setInputCol(\"text\") \\\n",
        "      .setOutputCol(\"document\")\n",
        "\n",
        "tokenizer = Tokenizer() \\\n",
        "      .setInputCols([\"document\"]) \\\n",
        "      .setOutputCol(\"token\")\n",
        "    \n",
        "normalizer = Normalizer() \\\n",
        "      .setInputCols([\"token\"]) \\\n",
        "      .setOutputCol(\"normalized\")\n",
        "\n",
        "stopwords_cleaner = StopWordsCleaner.pretrained(\"stopwords_sw\", \"sw\") \\\n",
        "        .setInputCols([\"normalized\"]) \\\n",
        "        .setOutputCol(\"cleanTokens\")\\\n",
        "        .setCaseSensitive(False)\n",
        "\n",
        "embeddings = XlmRoBertaEmbeddings.pretrained(\"xlm_roberta_base_finetuned_swahili\", \"sw\")\\\n",
        "    .setInputCols([\"document\", \"cleanTokens\"])\\\n",
        "    .setOutputCol(\"embeddings\")\n",
        "\n",
        "embeddingsSentence = SentenceEmbeddings() \\\n",
        "      .setInputCols([\"document\", \"embeddings\"]) \\\n",
        "      .setOutputCol(\"sentence_embeddings\") \\\n",
        "      .setPoolingStrategy(\"AVERAGE\")\n",
        "\n",
        "sentimentClassifier = ClassifierDLModel.pretrained(\"classifierdl_xlm_roberta_sentiment\", \"sw\") \\\n",
        "  .setInputCols([\"document\", \"sentence_embeddings\"]) \\\n",
        "  .setOutputCol(\"class\")\n",
        "\n",
        "sw_pipeline = Pipeline(stages=[document_assembler, tokenizer, normalizer, stopwords_cleaner, embeddings, embeddingsSentence, sentimentClassifier])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stopwords_sw download started this may take some time.\n",
            "Approximate size to download 1.5 KB\n",
            "[OK!]\n",
            "xlm_roberta_base_finetuned_swahili download started this may take some time.\n",
            "Approximate size to download 994.1 MB\n",
            "[OK!]\n",
            "classifierdl_xlm_roberta_sentiment download started this may take some time.\n",
            "Approximate size to download 21.9 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZsG9a2ST70t"
      },
      "source": [
        "## 5. Run the pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8k_omsF6T8S0"
      },
      "source": [
        "model = sw_pipeline.fit(spark.createDataFrame(pd.DataFrame({'text': ['']})))\n",
        "\n",
        "result = model.transform(spark.createDataFrame(pd.DataFrame({'text': text_list})))\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKVc3bTmVQj3"
      },
      "source": [
        "## 6. Visualize results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kElw6v7iVRea",
        "outputId": "49effb7a-41a0-4fdb-c550-7ba801a8f1e9"
      },
      "source": [
        "\n",
        "result.select(F.explode(F.arrays_zip('document.result', 'class.result')).alias(\"cols\")) \\\n",
        ".select(\n",
        "        F.expr(\"cols['0']\").alias(\"chunk\"),\n",
        "        F.expr(\"cols['1']\").alias('result')).show(truncate=False)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------------------------------------------------------------------------------------+--------+\n",
            "|chunk                                                                                                        |result  |\n",
            "+-------------------------------------------------------------------------------------------------------------+--------+\n",
            "|Tukio bora katika sinema ilikuwa wakati Gerardo anajaribu kupata wimbo ambao unaendelea kupitia kichwa chake.|Positive|\n",
            "|Ni dharau kwa akili ya mtu na upotezaji mkubwa wa pesa                                                       |Positive|\n",
            "|Kris Kristoffersen ni mzuri kwenye sinema hii na kweli hufanya tofauti.                                      |Positive|\n",
            "|Hadithi yenyewe ni ya kutabirika tu na ya uvivu.                                                             |Positive|\n",
            "|Ninapendekeza hizi kwa kuwa zinaonekana nzuri sana, kifahari na nzuri                                        |Positive|\n",
            "|Safaricom si muache kucheza na mkopo wa nambari yangu tafadhali. mnanifilisishaðŸ˜“ðŸ˜“ðŸ˜¯                        |Positive|\n",
            "|Bidhaa ilikuwa bora na inafanya kazi vizuri kuliko ya verizon na bei ilikuwa rahisi                          |Positive|\n",
            "|Siwezi kuona jinsi sinema hii inavyoweza kuwa msukumo kwa mtu yeyote kushinda woga na kukataliwa.            |Positive|\n",
            "|Sinema hii inasawazishwa vizuri na vichekesho na mchezo wa kuigiza na nilijifurahisha sana.                  |Positive|\n",
            "+-------------------------------------------------------------------------------------------------------------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "light_pipeline = LightPipeline(sw_pipeline.fit(spark.createDataFrame([['']]).toDF(\"text\")))\n",
        "\n",
        "result1 = light_pipeline.annotate(\"nataka uhuru ni president.\")\n",
        "\n",
        "result2 = light_pipeline.annotate(\"nataka chukula.\")\n",
        "\n",
        "print(result1, result2, sep = \"\\n\")"
      ],
      "metadata": {
        "id": "D0ABdhdCDQpY",
        "outputId": "5be938ea-9c6b-4678-c207-d8c47dc99ba3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'document': ['nataka uhuru ni president.'], 'normalized': ['nataka', 'uhuru', 'ni', 'president'], 'sentence_embeddings': ['nataka uhuru ni president.'], 'cleanTokens': ['nataka', 'uhuru', 'president'], 'token': ['nataka', 'uhuru', 'ni', 'president', '.'], 'class': ['Positive'], 'embeddings': ['nataka', 'uhuru', 'president']}\n",
            "{'document': ['nataka chukula.'], 'normalized': ['nataka', 'chukula'], 'sentence_embeddings': ['nataka chukula.'], 'cleanTokens': ['nataka', 'chukula'], 'token': ['nataka', 'chukula', '.'], 'class': ['Negative'], 'embeddings': ['nataka', 'chukula']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7GS5WQxjcXyW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}